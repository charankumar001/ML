{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPF7LSyQOPajh0MDAE5hfyv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charankumar001/ML/blob/main/3.%20ID3%20decision%20tree.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, attribute=None, value=None, results=None, true_branch=None,\n",
        "                 false_branch=None):\n",
        "        self.attribute, self.value, self.results, self.true_branch, self.false_branch = attribute, value, results, true_branch, false_branch\n",
        "\n",
        "def build_tree(rows):\n",
        "    if not rows:\n",
        "        return Node()\n",
        "    # Base case 1: All rows in the current set have the same class label\n",
        "    if len(set(row[-1] for row in rows)) == 1:\n",
        "        return Node(results=rows[0][-1])\n",
        "\n",
        "    num_attributes = len(rows[0]) - 1\n",
        "    best_gain = 0.0\n",
        "    best_criteria = None  # (attribute_index, value_to_split_on)\n",
        "\n",
        "    # Find the best attribute and the best value to split on\n",
        "    for col in range(num_attributes):\n",
        "        unique_values = set(row[col] for row in rows)\n",
        "        for value in unique_values:\n",
        "            # Split the dataset based on this attribute and value\n",
        "            set1 = [row for row in rows if row[col] == value]\n",
        "            set2 = [row for row in rows if row[col] != value]\n",
        "\n",
        "            # Calculate information gain for this potential split\n",
        "            # Avoid division by zero if a set is empty\n",
        "            p = float(len(set1)) / len(rows) if len(rows) > 0 else 0\n",
        "            current_gain = entropy(rows) - p * entropy(set1) - (1 - p) * entropy(set2)\n",
        "\n",
        "            if current_gain > best_gain:\n",
        "                best_gain = current_gain\n",
        "                best_criteria = (col, value)\n",
        "\n",
        "    # Base case 2: If no information gain, return a leaf node with the majority class\n",
        "    if best_gain == 0 and best_criteria is None: # This check for best_criteria might be redundant if best_gain==0 implies it\n",
        "        counts = class_counts(rows)\n",
        "        if counts: # Ensure counts is not empty for max() function\n",
        "            majority_class = max(counts, key=counts.get)\n",
        "            return Node(results=majority_class)\n",
        "        else:\n",
        "            return Node() # Should ideally not happen if rows is not empty\n",
        "\n",
        "    # Perform the split using the best criteria found\n",
        "    attribute_index, split_value = best_criteria\n",
        "\n",
        "    true_rows = [row for row in rows if row[attribute_index] == split_value]\n",
        "    false_rows = [row for row in rows if row[attribute_index] != split_value]\n",
        "\n",
        "    true_branch = build_tree(true_rows)\n",
        "    false_branch = build_tree(false_rows)\n",
        "\n",
        "    return Node(attribute=attribute_index, value=split_value, true_branch=true_branch,\n",
        "                false_branch=false_branch)\n",
        "\n",
        "def information_gain(rows, col):\n",
        "    # This function is now superseded by the in-build_tree gain calculation for binary splits\n",
        "    # However, it's still called by the original max() if we were to revert to that logic.\n",
        "    # For the current binary split logic, it's not strictly necessary in its original form.\n",
        "    # Leaving it for now, but its usage within build_tree is changed.\n",
        "    total_entropy = entropy(rows)\n",
        "    values = set(row[col] for row in rows)\n",
        "    weighted_entropy = sum(len(list(filter(lambda row: row[col] == val, rows))) / len(rows) *\n",
        "                           entropy(list(filter(lambda row: row[col] == val, rows))) for val in values)\n",
        "    return total_entropy - weighted_entropy\n",
        "\n",
        "def entropy(rows):\n",
        "    from math import log2\n",
        "    counts = class_counts(rows)\n",
        "    if not counts: # Handle case where counts is empty (e.g., empty rows list)\n",
        "        return 0.0\n",
        "    total_rows = sum(counts.values())\n",
        "    return -sum(count / total_rows * log2(count / total_rows) for count in counts.values())\n",
        "\n",
        "def class_counts(rows):\n",
        "    # Need to handle empty rows list to avoid ZeroDivisionError\n",
        "    if not rows:\n",
        "        return {}\n",
        "    # Correct way to count occurrences of each class label (last element in each row)\n",
        "    counts = {}\n",
        "    for row in rows:\n",
        "        label = row[-1]\n",
        "        counts[label] = counts.get(label, 0) + 1\n",
        "    return counts\n",
        "\n",
        "# Example dataset (you can modify this as needed)\n",
        "dataset = [\n",
        "    ['Sunny', 'Hot', 'High', 'Weak', 'No'],\n",
        "    ['Sunny', 'Hot', 'High', 'Strong', 'No'],\n",
        "    ['Overcast', 'Hot', 'High', 'Weak', 'Yes'],\n",
        "    ['Rain', 'Mild', 'High', 'Weak', 'Yes'],\n",
        "    ['Rain', 'Cool', 'Normal', 'Weak', 'Yes'],\n",
        "    ['Rain', 'Cool', 'Normal', 'Strong', 'No'],\n",
        "    ['Overcast', 'Cool', 'Normal', 'Strong', 'Yes'],\n",
        "    ['Sunny', 'Mild', 'High', 'Weak', 'No'],\n",
        "    ['Sunny', 'Cool', 'Normal', 'Weak', 'Yes'],\n",
        "    ['Rain', 'Mild', 'Normal', 'Weak', 'Yes']\n",
        "]\n",
        "\n",
        "# Build the decision tree\n",
        "tree = build_tree(dataset)\n",
        "\n",
        "# Print the decision tree\n",
        "def print_tree(node, indent=\"\"):\n",
        "    if node is None:\n",
        "        return\n",
        "    if node.results is not None:\n",
        "        print(indent + str(node.results))\n",
        "    else:\n",
        "        print(indent + f'Attribute {node.attribute} : {node.value}? ')\n",
        "        print(indent + '--> True:')\n",
        "        print_tree(node.true_branch, indent + '  ')\n",
        "        print(indent + '--> False:')\n",
        "        print_tree(node.false_branch, indent + '  ')\n",
        "\n",
        "print_tree(tree)\n",
        "\n",
        "# Classify a new sample\n",
        "new_sample = ['Sunny', 'Cool', 'High', 'Strong']\n",
        "current_node = tree\n",
        "while current_node.results is None and current_node.attribute is not None:\n",
        "    if new_sample[current_node.attribute] == current_node.value:\n",
        "        current_node = current_node.true_branch\n",
        "    else:\n",
        "        current_node = current_node.false_branch\n",
        "\n",
        "print(f\"\\nClassification result for {new_sample}: {current_node.results}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4sBziYyezgE",
        "outputId": "d497a557-cebc-4493-a7b9-9431e8429e47"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attribute 0 : Sunny? \n",
            "--> True:\n",
            "  Attribute None : None? \n",
            "  --> True:\n",
            "  --> False:\n",
            "--> False:\n",
            "  Attribute None : None? \n",
            "  --> True:\n",
            "  --> False:\n",
            "\n",
            "Classification result for ['Sunny', 'Cool', 'High', 'Strong']: None\n"
          ]
        }
      ]
    }
  ]
}